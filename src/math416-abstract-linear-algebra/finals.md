TODO
* ON bases for Polynomial IPS with different IPs

Vector space over R
: A vector space V over a field F is a set,
  along with two binary operation $+: V\times V \to V$ and $.: F\times V \to V$
  such that, for all $a, b \in V, k \in F$,
  * $V$ is not empty
  * Addition is Abelian Group
    - Closed
    - Associative
    - Identity
    - Inverse
    - Commutative
  * Scalar multiplication
    - Closed
    - Associative
    - Identity
    - Inverse
  * Distributive (left and right)

Subspace W of V
: Subset of V such that W is a VS under the same operations (multiplication, +) as V

subspace test
: Subset of V, such that
  - nonempty
  - Closed over scalar
    * multiplication
    * addition 
    * inverses

linear combination
: A vector $v \in V$ is said to be a linear combination of vectors $S \subset V$
iff $\exist a_1, a_2... a_n \in F$ and $v_1... v_n \in V$ such that $a_1v_1 +
... a_nv_n = v$

Span(S)
: Set of all linear combinations of vectors in $S

  S spans V iff Span(S) = V

Linearly dependent
: The set $S$ is said to be linearly dependent iff
  $\exist a_1...a_n \in F$ such that
  $a_1 v_1 + ... + a_n v_n = 0$, where at least one $a_i \ne 0$

Linearly independent
: $\forall a_1...a_n \in F$
  $a_1 v_1 + ... + a_n v_n = 0 \Longrightarrow a_1 = a_2 ... = a_n = 0$

Basis
: * Linearly independent
  * Generates

Dimension
: Cardinality of the bases of the VS


Linear Transformation
: Let V vs, $T: V \to V$. Then $T$ is a linear transform if, $\forall x, y \in
V$
  * T(a + b) = T(a) + T(B)
  * T(ka) = T(a)

Null space
: $\{ v \in V: T(v) = 0 \}$

Range
: $\{ T(v): v \in V\}$

Ordered basis
: Sequence of linearly  independent vectors that generate V

Coordornate vector
: Given ordered basis \beta, the unique set of scalars $a1, a2... an$ such that
  $\sum a_i b_i = v$, then $(a_1, a_2... a_n)$ is the coordinate vector of v.

Matrix rep of T
: Given vector spaces V and W, linear $T: V \to W$, ordered bases $\{v_n\},
\{w_n\}$, such that $T(v_i) = \sum a_ij w_j$ ($(a_i1, a_i2... a_in)$ is the coordinate vector of $T(v_i)$ w.r.t $\{w_n\}$. Then the matrix $M$ such that $M_{ij} = a_{ij}$ is the matrix representation of $T$
T()

Matrix Multiplication
: $(ab)_{ij} = \sum a_ik b_kj$

Inverse of a linear transformation
: If $T$ is a linear transform, then $T ^{-1}$ is the inverse of $T$ iff
  * $TT ^{-1} = I$

Isomorphism
: Let $U, V$ be two vector spaces, if there exists $T$, invertable from $U \to
V$ then $u, V$ are isomorphic.

Dimension Theorem
: Nullity + Rank \le dim(V)

Self-adjoint
: If $A^* = A$

Normal
: If $AA^* = A^* A$

Unitary operator
: If F = C, $\|T(x)\| = \|x\|$



Orthogonal operator
: If F = R, $\|T(x)\| = \|x\|$

Orthogonal Matrix
: If $A^tA = AA^t = I$

Unitary Matrix
: If $A*A = AA* = I$


---

Replacement theorem
: $V$ has dimension $n$, generated by $G$.
  $L$ is linearly independent set of $m$ vectors.
  $m \le n$, $\exists M \subset G, containing $n - m$ vectors, and $M \cup L$
  generates $V$ 

  Proof by induction
  : * Obvious for empty $L$
    * $m \le n$ otherwise linear independence of $L$ is compromised
    * XXX

A matrix $M$ is in RREF iff
: * $M_{ii} = 1$
  * $i > j \Longrightarrow M_{ij) = 0$
  * zero rows are at the bottom

: * Leading co-efficient of each row is 1
  * Zero rows are at the bottom

---

Let $w_1 \in W_1 \notin W_2$, $w_2 \in W_2 \notin W_1$

Then $w_1 + w_2 \in Union$ since VSs are closed

So $x = w_1 + w_2$ must be in either $W_1$ or $W_2$
WLOG, assum in W1
Then x - w1 \in W1 = w1 + w2 - w1 = w2, contradtiction


